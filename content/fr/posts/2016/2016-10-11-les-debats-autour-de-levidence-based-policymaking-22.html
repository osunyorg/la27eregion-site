---
title: >-
  Les débats autour de l’« evidence-based policymaking » (2/2)
subtitle: >-
  
bodyclass: >-
   
url: "/fr/productions/publications/2016-10-11-les-debats-autour-de-levidence-based-policymaking-22/"
slug: "les-debats-autour-de-levidence-based-policymaking-22"
date: 2016-10-11T14:07:26+02:00
lastmod: 2025-05-14T16:19:53+02:00
meta:
  hugo:
    permalink: "/fr/productions/publications/2016-10-11-les-debats-autour-de-levidence-based-policymaking-22/"
    path: "/posts/2016/2016-10-11-les-debats-autour-de-levidence-based-policymaking-22"
    file: "content/fr/posts/2016/2016-10-11-les-debats-autour-de-levidence-based-policymaking-22.html"
    slug: "les-debats-autour-de-levidence-based-policymaking-22"
  dates:
    created_at: 2025-05-14T16:08:32+02:00
    updated_at: 2025-05-14T16:19:53+02:00
    published_at: 2016-10-11T14:07:26+02:00
search:
  id: "c8638575-8638-4859-a7a9-3cbc20502eb9"
  about_id: "5bf3261c-5047-4e83-ad68-d525365db368"
  url: "/fr/productions/publications/2016-10-11-les-debats-autour-de-levidence-based-policymaking-22/"
  kind: "Communication::Website::Post::Localization"
  lang: "fr"
  title: >-
    Les débats autour de l’« evidence-based policymaking » (2/2)
  summary: >-
    <p>Après une licence de sociologie à la London School of Economics, Cécilia Barbry y a également réalisé un master en politiques publiques. C’est dans ce cadre qu’elle a écrit un mémoire sur les liens entre l’« evidence-based policymaking » (dont il est question ici) et la politique de santé mentale au Royaume-Uni. Après des expériences professionnelles en collectivité en France, dans des ONGs en Bolivie, dans un établissement pénitentiaire au Portugal et au Parlement à Londres, elle travaille actuellement chez <a href="http://www.asdo-etudes.fr/" target="_blank" rel="noreferrer">ASDO Études <span class="sr-only">(lien externe)</span></a>, un cabinet d’études sociologiques appliquées aux politiques publiques.</p>
  body: >-
    <p>  <br>Elle nous a très gentillement permis de reproduire cet article, rédigé par ses soins, sur notre blog. Nous espérons qu’il vous éclairera autant qu’il nous éclairera sur les enjeux du courant « evidence-based ». ———————————— Présent dans les pays anglo-saxons depuis plusieurs années, le courant «  evidence-based  » est de plus en plus souvent érigé comme un modèle à suivre dans les pratiques des politiques publiques et du développement international, même si des voix commencent à s’élever pour en pointer les limites.  Notre premier article permettait d’ailleurs d’effectuer un rapide tour d’horizon du sujet . Si, dans sa forme idéale l’EBPM fait quasiment l’unanimité, de nombreuses voix s’élèvent pour mettre en garde contre une vision peut-être un peu naïve de la réalité qui préconise des « solutions miracles » à coup de « baguette magique ». Ainsi, cette seconde partie développe les trois éléments qui concentrent en particulier les critiques autour de l’EBPM. ———————————— Les politiques publiques ont rarement un développement linéaire et mécanique Comme indiqué précédemment, l’idéal de l’EBPM prévoit que le décideur public observe un problème, les scientifiques lui indiquent quelle est la solution la plus adéquate, et celle-ci est ensuite implémentée sans interférences. Dans la réalité, les choses se passent rarement de façon aussi simple. De nombreux auteurs dont  Lindblom  ou  Forester  ont montré à quel point le processus des politiques publiques est souvent beaucoup plus chaotique que linéaire. Premièrement, les décideurs publics font face à ce que les auteurs appellent une «  bounded rationality  », une rationalité limitée. En effet, il est pratiquement impossible d’atteindre l’omniscience prônée par le modèle idéal de l’EBPM. Il y a tout d’abord une limite de temps, parfois imposée par les cycles législatifs ou exécutifs, parfois imposée par l’urgence des événements qui nécessitent une réponse immédiate. Les décideurs publics ne disposent alors pas du temps nécessaire pour identifier toutes les solutions possibles et les évaluer de manière systématique. La plupart du temps ils font du «  satisficing  », c’est-à-dire qu’ils se contentent d’une solution lorsqu’elle atteint un niveau jugé satisfaisant. Liée à la limite de temps, il y a aussi une limite de distance nécessaire à une prise de décision en toute connaissance de cause. Personne ne peut savoir si une autre étude, mesurant des aspects différents, n’aurait pas pointé vers une meilleure solution. Personne ne connait non plus les effets à long terme d’une solution choisie, ni ses effets indirects, ou ses coûts d’opportunité, par rapport à ceux d’une autre option. Ensuite, il y a souvent non pas un mais plusieurs acteurs impliqués dans la prise de décision. Il y a une division du travail qui peut entraîner de nombreuses difficultés, avec des décideurs qui n’ont pas forcément les mêmes interprétations du problème, qui communiquent mal entre eux, ou qui ne coordonnent pas toujours leurs actions. Prenons, par exemple, le problème de la criminalité. Il y a de nombreux acteurs qui travaillent à apporter des solutions : le personnel du ministère de la justice, celui du ministère de l’intérieur, le personnel de l’administration pénitentiaire, ainsi que tous les acteurs du secteur social avec les assistants sociaux, les éducateurs, les associations. Sans parler de tous ceux qui travaillent à la prévention de la criminalité, notamment dans les politiques jeunesses. Chaque organisation a sa propre manière particulière de travailler avec ses propres objectifs stratégiques, ses moyens, et ses actions. Chacun déclenche des effets à des échelles différentes, mais personne ne décide ou ne contrôle de manière unilatérale les actions à mener à tous les niveaux. Enfin, il est rare de voir la mise en œuvre d’une politique suivre parfaitement ce qui était prévu à des échelons supérieurs. Il y a souvent des écarts considérables entre la théorie et la pratique, et beaucoup des effets d’une politique dépendent finalement davantage de la qualité de la mise en œuvre et des compétences du personnel sur le terrain, que de la stratégie de départ décidée en amont. On a beau déterminer que de suivre des cours de nutrition à l’école aide à lutter contre l’obésité infantile, on n’est jamais à l’abri d’un écart de performance entre les différents intervenants qui influerait de manière significative sur le résultat final. De nombreuses interventions sont ainsi impossibles à standardiser et il est souvent plus utile de chercher à comprendre  pourquoi  l’intervention a marché au départ, plutôt que de ne s’intéresser qu’à la technique particulière qui a été utilisée. Or c’est quelque chose qui est souvent ignoré dans l’EBPM. Comme le disent  Cartwright et Hardie , « afin de pouvoir passer de « ceci a marché là-bas » à « ceci marchera ici », il faut d’abord comprendre qu’est-ce qui a fait exactement que « ceci » marche « là-bas ». La « preuve » est rarement un élément objectif et incontesté L’autre débat concerne la nature de la « preuve ». En effet, il n’est pas aussi simple qu’il y paraît de déterminer de manière catégorique ce qui marche et ce qui ne marche pas. Tout d’abord, il y a un débat méthodologique car il existe de nombreuses manières de faire de la recherche académique. Au-delà de la division classique entre méthodes qualitatives et quantitatives, il y a des différences au sein même de ces catégories. Chez les partisans les plus positivistes de l’EBPM, la référence en matière de méthodologie est l’essai randomisé contrôlé (RCT en anglais, pour  Randomised Controlled Trial ). L’essai randomisé contrôlé est un type d’étude inspiré de la recherche en médecine dans lequel les sujets traités sont répartis de manière aléatoire entre les différents traitements et un groupe contrôle. Ce système permet, d’une part, de pouvoir éliminer les biais de sélection, et d’autre part, de pouvoir prouver que c’est bien le traitement qui est à l’origine de l’effet observé. Selon eux c’est le seul moyen de pouvoir déterminer avec objectivité ce qui marche et ce qui ne marche pas. Cependant, cette idée que l’on peut déterminer de manière complètement objective quelle est la meilleure solution et découvrir « la vérité » incontestable est à nouveau considérée par certains comme une illusion un peu naïve. En effet, on ne « découvre » généralement pas la preuve de ce qui marche, on teste des hypothèses. Celles-ci ont besoin d’être au préalable « opérationnalisées », c’est-à-dire que l’on doit choisir des indicateurs afin de pouvoir mesurer des concepts. Par exemple, pour déterminer si un programme est efficace pour lutter contre la délinquance, il faut choisir des indicateurs pour mesurer « la délinquance » ainsi que « l’efficacité » du programme. C’est dans cette phase-là qu’interviennent inévitablement les choix et les jugements de valeur contestables que peuvent faire les chercheurs. La recherche quantitative est parfois perçue comme plus objective parce qu’elle repose sur des chiffres, mais comme le montre  Majone , les chiffres subissent des transformations. Ils commencent par être des données brutes, puis ils sont ensuite regroupés dans des catégories, comparés, et deviennent des moyennes, des taux, des ratios, des pourcentages. Chaque étape de transformation comporte un risque de partialité parce que les chercheurs choisissent les références qu’ils considèrent comme pertinentes. Par exemple, on peut choisir de montrer une augmentation du pouvoir d’achat entre deux dates, donnant une impression positive, alors que si l’on prend une période plus large on se rend compte que l’augmentation en question est dérisoire par rapport à la tendance générale à la baisse depuis plusieurs décennies. On peut aussi utiliser des éléments de langage qui changent le sens des chiffres. Par exemple, on peut choisir de dire « ce médicament guérit 70% des patients » ou alors « ce médicament échoue à sauver 30% des patients ». Les chiffres sont exactement les mêmes, mais l’effet sur le lecteur est complètement différent. On peut choisir également de montrer certains chiffres, et d’en ignorer d’autres. Par exemple, on va se réjouir des chiffres du chômage qui baissent, alors qu’ils cachent souvent l’augmentation du travail précaire. C’est ainsi que l’on peut souvent jouer avec les chiffres, et leur faire dire ce que l’on veut. De nombreux auteurs ont montré à quel point la science était à présent devenue une arme en politique, pour donner une validation à son propos. On se sert souvent de la science pour rationaliser une décision prise en amont pour d’autres motifs. C’est souvent le prestige de la science, plutôt que la science elle-même, qui devient importante, et personne ne prend la peine de vérifier la véracité des propos. Sous couvert d’avoir « la science » de son côté, on peut justifier n’importe quelle idée. C’est une stratégie que l’on a retrouvé lors du débat sur le Brexit, lorsque l’on a vu les deux camps brandir des chiffres (souvent manipulés) pour justifier leur politique de maintien ou de sortie de l’Union Européenne. C’est entre autres le fait que la véracité des chiffres ne soit plus un argument convaincant  qui a fait dire à plusieurs auteurs  que nous étions entrés dans une ère « post-factuelle » ou un ère de « post-vérité ». Une autre indication du fait que la « science » n’est pas une réalité objective est que la recherche sur un même sujet peut produire des résultats différents selon les études. Cela montre à quel point le choix du chercheur en matière d’indicateurs peut changer complètement le résultat d’une étude. En effet, le modèle idéal de l’EBPM ne prévoit pas du tout que la communauté scientifique puisse ne pas être d’accord sur les solutions à apporter à un problème. Pourtant c’est un cas de figure qui arrive assez souvent. En réalité, si l’on n’utilise pas plus souvent l’EBPM, c’est surtout parce que l’on n’arrive pas toujours à apporter une réponse claire et unanime sur les sujets qui font débat. La réalité de la recherche scientifique est que beaucoup d’études n’ont pas forcément de résultats probants. Malheureusement, la population générale et la classe politique ont souvent une culture scientifique insuffisante pour pouvoir apprécier les forces et les faiblesses de la recherche scientifique et les nuances de ses conclusions.  Hilgartner  montre comment, pour que la recherche soit convaincante, la science doit souvent être mise en spectacle : les possibilités deviennent des certitudes, les doutes sont habilement passés sous silence, et de manière générale toutes les controverses méthodologiques ou les jeux de pouvoir sont maintenus en coulisses afin de garantir une image d’unicité et d’objectivité, et réussir à convaincre ceux qu’il faut convaincre. Tous ces éléments mettent en évidence le fait que la science et les « preuves » ne sont pas des réalités objectives que le chercheur tente simplement de découvrir, et que les résultats sont liés aux questions posées et aux moyens utilisés pour les déterminer. Enfin, outre le débat méthodologique, se pose aussi la question non moins délicate d’arriver à mesurer ce qui est important, et ne pas se contenter de rendre important ce qui est facilement mesurable. C’est particulièrement le cas en ce qui concerne les évaluations. Comme le montrent  Bevan et Hood , il faut faire attention au problème de la synecdoque. Comme dans la figure littéraire, lorsque l’on choisit des indicateurs, on prend une partie d’un ensemble pour représenter le tout. Mais pour que l’évaluation soit pertinente, il faut s’assurer du fait que l’on peut réellement compter sur les indicateurs choisis pour donner une représentation adéquate de l’intervention. De la même manière, il faut s’assurer que l’on n’oublie pas de rendre compte de quelque chose de fondamental, tout simplement parce que l’on n’a pas réussi à le mesurer. Dans un système où l’on ne croit que ce que l’on peut prouver, une difficulté à mesurer un phénomène peut avoir de lourdes conséquences sur le futur d’une politique. Inversement, on risque aussi de favoriser les interventions qui sont facilement mesurables. C’est pour cela qu’il est indispensable d’élargir la notion d’évaluation au-delà du simple relevé d’indicateurs. Ce dernier point peut être illustré par la politique de santé mentale actuelle au Royaume-Uni. Depuis 2007, le gouvernement a mis en place une politique publique pour tenter d’apporter une réponse à l’épidémie de dépression et d’anxiété à laquelle fait face la population. Poursuivant l’objectif de l’EBPM, le gouvernement a décidé de se baser sur la recherche scientifique, et surtout les essais randomisés contrôlés, pour déterminer quel type de thérapie était la plus efficace pour lutter contre la dépression et l’anxiété. Après avoir fait une revue des différentes études comparant les différents types de thérapie, le gouvernement a déterminé que c’étaient les thérapies cognitives et comportementales qui étaient les plus efficaces. Cependant, une analyse précise des résultats statistiques des études montre que les thérapies cognitives et comportementales ne sont pas aussi supérieures aux autres que ce qui a été annoncé publiquement. Il s’avère en réalité que le choix de favoriser ces thérapies se base moins sur la justification scientifique de leur efficacité que sur le fait que ce sont le type de thérapies qui sont les plus faciles à évaluer, et donc pour lesquelles on a tout simplement plus d’études… Dans un contexte qui pousse à la transparence à tout prix, et à la production de chiffres pour justifier ses interventions, celles qui arrivent à en produire facilement sont souvent favorisées au détriment de celles qui y arrivent moins. Par un effet presque pervers, la pression de la transparence et de la « preuve » à tout prix peut mener à la mise en place de politiques publiques qui ne sont pas forcément les meilleures dans l’absolu. L’importance de l’ « irrationalité »  Enfin, il existe une troisième catégorie de critiques qui questionne la quête de la rationalité absolue à tout prix. L’un des postulats premiers de l’EBPM est que les décisions rationnelles sont meilleures pour la société que celles qui sont basées sur des considérations d’ordre politique ou religieux, par exemple. Cependant, pour assurer le bien-être de la société humaine, il est parfois nécessaire de faire des entorses à cet idéal et prendre en compte certaines considérations politiques, morales ou éthiques au-delà de ce qui est purement rationnel. L’un des domaines dans lequel ces considérations prennent tout leur sens est celui de la santé. Pour un gouvernement, financer une politique de santé est généralement un financement à perte. Certes, un individu en bonne santé rapporte de l’argent au gouvernement à travers ses impôts et la richesse produite par son travail, et il est donc économiquement rationnel pour un gouvernement de maintenir ses citoyens en bonne santé. Cependant, la valeur économique d’un individu varie en fonction de son âge. Lorsqu’un individu âgé contracte une Affection de Longue Durée, il n’est plus économiquement utile au gouvernement. Néanmoins, il paraîtrait impensable de déclarer qu’on ne va pas gâcher des milliers d’euros pour sauver un homme de 85 ans atteint d’un cancer puisque son espérance de vie au départ n’est de toute façon plus très importante à ce stade-là. Le thème de l’allocation des ressources dans le domaine de la santé est un sujet fascinant où rationalité scientifique, rationalité économique, et considérations éthiques se mêlent et se débattent. Pour reprendre l’exemple du terrorisme évoqué précédemment, il n’est certes pas  rationnel  de dépenser autant d’argent pour lutter contre les attaques terroristes si l’on ne prend en compte que le nombre de morts effectifs, par rapport aux morts causés par plein d’autres phénomènes. Cependant il y a plein d’autres facteurs qui en font une intervention légitime, comme les considérations politiques, diplomatiques, sécuritaires, ou même psychologiques. Pour éviter un vent de panique dans la population qui peut avoir des conséquences désastreuses à de nombreux niveaux, il est nécessaire d’intervenir ne serait-ce que pour avoir un effet rassurant psychologiquement. L’EBPM oublie souvent de prendre en compte l’aspect psychologique des interventions. De manière plus générale, certaines oppositions à l’EBPM relèvent d’un débat de valeurs. Un certain nombre de personnes s’élèvent contre le culte de la rationalité à tout prix, celui de l’optimisation, du pragmatisme et de l’utilitarisme dans toutes les pratiques (voir par exemple  cet article de Libération ). Dans une société qui prône la rationalité, la non-optimisation de ses pratiques est devenue une faute presque morale à éviter à tout prix. C’est le cas par exemple de la perte de temps et la perte d’argent. Quelqu’un qui ne sait pas faire les choses rapidement, ou qui ne sait pas trouver le meilleur rapport qualité/prix sera critiqué. Cependant les hommes ont déjà montré aux économistes classiques qu’ils ne sont pas, comme ils le pensaient au départ, des «  homo economicus  », parfaitement rationnels, qui n’ont comme seul objectif que la maximisation de leur utilité. Ils peuvent parfois faire preuve d’altruisme, se sacrifier pour le bénéfice d’un autre, changer de comportement parce qu’ils sont émus et affectés par les conditions des autres, passer du temps à contempler de l’art, trouver du plaisir à prendre leur temps pour faire les choses, ou se satisfaire de payer un prix donné, même s’il ne s’agit pas du prix le plus rentable possible. Le débat de valeur nous amène à nous demander si dans notre quête constante d’optimisation, on ne perd pas un élément essentiel à notre bien-être.  Barry Schwartz  nous avait déjà démontré que, contrairement à ce que l’on pourrait penser, plus on a de choix, plus on est malheureux. En effet, plus on a de choix, plus on va s’attacher à vouloir faire le meilleur des choix possibles, plus on va s’attacher à des détails insignifiants, et plus on risque d’être déçus à la fin car à la moindre imperfection on se demandera toujours si un autre choix n’aurait pas été meilleur. Alors que quelqu’un qui choisit la première option satisfaisante qu’il voit (bien que pas forcément la plus rentable rationnellement) s’épargne de nombreuses heures d’agonie à comparer tous les détails de toutes les options, ainsi que les heures à douter de son choix une fois celui-ci effectué. Dans le contexte des politiques publiques, cela pourrait se traduire par exemple par le développement de temps purement ludiques sans aucune vocation éducative particulière dans l’organisation du temps scolaire, par le maintien d’une politique culturelle active malgré la difficulté de justifier sa plus-value avec les indicateurs et les mesures classiques d’évaluations, ou par le choix de partenaires économiquement et socialement responsables malgré leurs prix plus élevés. ———————————— En conclusion, l’EBPM est un sujet passionnant qui reflète bien l’époque dans laquelle nous nous trouvons : les progrès scientifiques élargissent le champ de nos connaissances et il est légitime de vouloir les utiliser. Nous voulons nous en servir pour améliorer les politiques publiques et les rendre plus efficaces et plus en adéquation avec les besoins des citoyens. A cela s’ajoute une volonté de rationaliser nos actions de manière générale, d’améliorer les process, de systématiser et d’optimiser nos solutions. Cependant il faut veiller à ne pas considérer l’EBPM comme une « solution miracle » et à ne pas apporter des réponses simplistes et naïves à des problèmes extrêmement complexes. Il faut également veiller à ne pas admettre aveuglément des solutions proposées parce qu’elles sont soi-disant « objectives » et « scientifiques ». Une utilisation intelligente de la recherche scientifique ne dispense pas d’avoir une pensée critique et éclairée des opportunités, mais aussi des limites, du courant «  evidence-based  ».</p>

breadcrumbs:
  - title: >-
      Accueil
    path: "/fr/"
  - title: >-
      Productions
    path: "/fr/productions/"
  - title: >-
      Publications
    path: "/fr/productions/publications/"
  - title: >-
      Les débats autour de l’« evidence-based policymaking » (2/2)

design:
  full_width: false
  toc:
    present: false
    offcanvas: false

translationKey: communication-website-post-5bf3261c-5047-4e83-ad68-d525365db368

image:
  id: "7101d6c7-0126-4007-a0ea-c134ae494202"
  alt: ""
  credit: >-
    


meta_description: >-
  

summary: >-
  <p>Après une licence de sociologie à la London School of Economics, Cécilia Barbry y a également réalisé un master en politiques publiques. C’est dans ce cadre qu’elle a écrit un mémoire sur les liens entre l’« evidence-based policymaking » (dont il est question ici) et la politique de santé mentale au Royaume-Uni. Après des expériences professionnelles en collectivité en France, dans des ONGs en Bolivie, dans un établissement pénitentiaire au Portugal et au Parlement à Londres, elle travaille actuellement chez <a href="http://www.asdo-etudes.fr/" target="_blank" rel="noreferrer">ASDO Études <span class="sr-only">(lien externe)</span></a>, un cabinet d’études sociologiques appliquées aux politiques publiques.</p>

header_cta:
  display: false
  label: >-
    
  target: ""
  external: false
posts_categories:
  - "article"
taxonomies:
  - name: >-
      Catégories
    slug: ""
    path: ""
    categories:
      - permalink: "/fr/productions/publications/article/"
        path: "/posts_categories/article"
        slug: "article"
        file: "content/fr/posts_categories/article/_index.html"
        name: >-
          Article


contents_reading_time:
  seconds: 903
  text: >-
    15 minutes
contents:
  - kind: block
    template: chapter
    title: >-
      
    slug: >-
      
    ranks:
      base: 2
    top:
      active: false
    data:
      layout: no_background
      text: >-
        <p><em>Elle nous a très gentillement permis de reproduire cet article, rédigé par ses soins, sur notre blog. Nous espérons qu’il vous éclairera autant qu’il nous éclairera sur les enjeux du courant « evidence-based ».</em></p><p>————————————</p><p>Présent dans les pays anglo-saxons depuis plusieurs années, le courant « <em>evidence-based</em> » est de plus en plus souvent érigé comme un modèle à suivre dans les pratiques des politiques publiques et du développement international, même si des voix commencent à s’élever pour en pointer les limites. <a href="http://www.la27eregion.fr/quest-ce-que-le-courant-evidence-based-dans-les-politiques-publiques-12" target="_blank" rel="noreferrer">Notre premier article permettait d’ailleurs d’effectuer un rapide tour d’horizon du sujet <span class="sr-only">(lien externe)</span></a>. Si, dans sa forme idéale l’EBPM fait quasiment l’unanimité, de nombreuses voix s’élèvent pour mettre en garde contre une vision peut-être un peu naïve de la réalité qui préconise des « solutions miracles » à coup de « baguette magique ». Ainsi, cette seconde partie développe les trois éléments qui concentrent en particulier les critiques autour de l’EBPM.</p><p>————————————</p><p><em><strong>Les politiques publiques ont rarement un développement linéaire et mécanique</strong></em></p><p>Comme indiqué précédemment, l’idéal de l’EBPM prévoit que le décideur public observe un problème, les scientifiques lui indiquent quelle est la solution la plus adéquate, et celle-ci est ensuite implémentée sans interférences. Dans la réalité, les choses se passent rarement de façon aussi simple. De nombreux auteurs dont <a href="https://faculty.washington.edu/mccurdy/SciencePolicy/Lindblom%20Muddling%20Through.pdf" target="_blank" rel="noreferrer">Lindblom <span class="sr-only">(lien externe)</span></a> ou <a href="http://sciencepolicy.colorado.edu/students/envs_5720/forester_1984.pdf" target="_blank" rel="noreferrer">Forester <span class="sr-only">(lien externe)</span></a> ont montré à quel point le processus des politiques publiques est souvent beaucoup plus chaotique que linéaire.</p><p>Premièrement, les décideurs publics font face à ce que les auteurs appellent une « <em>bounded rationality</em> », une rationalité limitée. En effet, il est pratiquement impossible d’atteindre l’omniscience prônée par le modèle idéal de l’EBPM. Il y a tout d’abord une limite de temps, parfois imposée par les cycles législatifs ou exécutifs, parfois imposée par l’urgence des événements qui nécessitent une réponse immédiate. Les décideurs publics ne disposent alors pas du temps nécessaire pour identifier toutes les solutions possibles et les évaluer de manière systématique. La plupart du temps ils font du « <em>satisficing</em> », c’est-à-dire qu’ils se contentent d’une solution lorsqu’elle atteint un niveau jugé satisfaisant. Liée à la limite de temps, il y a aussi une limite de distance nécessaire à une prise de décision en toute connaissance de cause. Personne ne peut savoir si une autre étude, mesurant des aspects différents, n’aurait pas pointé vers une meilleure solution. Personne ne connait non plus les effets à long terme d’une solution choisie, ni ses effets indirects, ou ses coûts d’opportunité, par rapport à ceux d’une autre option.</p><p>Ensuite, il y a souvent non pas un mais plusieurs acteurs impliqués dans la prise de décision. Il y a une division du travail qui peut entraîner de nombreuses difficultés, avec des décideurs qui n’ont pas forcément les mêmes interprétations du problème, qui communiquent mal entre eux, ou qui ne coordonnent pas toujours leurs actions. Prenons, par exemple, le problème de la criminalité. Il y a de nombreux acteurs qui travaillent à apporter des solutions : le personnel du ministère de la justice, celui du ministère de l’intérieur, le personnel de l’administration pénitentiaire, ainsi que tous les acteurs du secteur social avec les assistants sociaux, les éducateurs, les associations. Sans parler de tous ceux qui travaillent à la prévention de la criminalité, notamment dans les politiques jeunesses. Chaque organisation a sa propre manière particulière de travailler avec ses propres objectifs stratégiques, ses moyens, et ses actions. Chacun déclenche des effets à des échelles différentes, mais personne ne décide ou ne contrôle de manière unilatérale les actions à mener à tous les niveaux.</p><p>Enfin, il est rare de voir la mise en œuvre d’une politique suivre parfaitement ce qui était prévu à des échelons supérieurs. Il y a souvent des écarts considérables entre la théorie et la pratique, et beaucoup des effets d’une politique dépendent finalement davantage de la qualité de la mise en œuvre et des compétences du personnel sur le terrain, que de la stratégie de départ décidée en amont. On a beau déterminer que de suivre des cours de nutrition à l’école aide à lutter contre l’obésité infantile, on n’est jamais à l’abri d’un écart de performance entre les différents intervenants qui influerait de manière significative sur le résultat final. De nombreuses interventions sont ainsi impossibles à standardiser et il est souvent plus utile de chercher à comprendre <em>pourquoi </em>l’intervention a marché au départ, plutôt que de ne s’intéresser qu’à la technique particulière qui a été utilisée. Or c’est quelque chose qui est souvent ignoré dans l’EBPM. Comme le disent <a href="https://www.timeshighereducation.com/books/evidence-based-policy-a-practical-guide-to-doing-it-better/422011.article" target="_blank" rel="noreferrer">Cartwright et Hardie <span class="sr-only">(lien externe)</span></a>, « afin de pouvoir passer de « ceci a marché là-bas » à « ceci marchera ici », il faut d’abord comprendre qu’est-ce qui a fait exactement que « ceci » marche « là-bas ».</p><p><em><strong>La « preuve » est rarement un élément objectif et incontesté</strong></em></p><p>L’autre débat concerne la nature de la « preuve ». En effet, il n’est pas aussi simple qu’il y paraît de déterminer de manière catégorique ce qui marche et ce qui ne marche pas.</p><p>Tout d’abord, il y a un débat méthodologique car il existe de nombreuses manières de faire de la recherche académique. Au-delà de la division classique entre méthodes qualitatives et quantitatives, il y a des différences au sein même de ces catégories. Chez les partisans les plus positivistes de l’EBPM, la référence en matière de méthodologie est l’essai randomisé contrôlé (RCT en anglais, pour <em>Randomised Controlled Trial</em>).</p><p>L’essai randomisé contrôlé est un type d’étude inspiré de la recherche en médecine dans lequel les sujets traités sont répartis de manière aléatoire entre les différents traitements et un groupe contrôle. Ce système permet, d’une part, de pouvoir éliminer les biais de sélection, et d’autre part, de pouvoir prouver que c’est bien le traitement qui est à l’origine de l’effet observé. Selon eux c’est le seul moyen de pouvoir déterminer avec objectivité ce qui marche et ce qui ne marche pas.</p><p>Cependant, cette idée que l’on peut déterminer de manière complètement objective quelle est la meilleure solution et découvrir « la vérité » incontestable est à nouveau considérée par certains comme une illusion un peu naïve. En effet, on ne « découvre » généralement pas la preuve de ce qui marche, on teste des hypothèses. Celles-ci ont besoin d’être au préalable « opérationnalisées », c’est-à-dire que l’on doit choisir des indicateurs afin de pouvoir mesurer des concepts. Par exemple, pour déterminer si un programme est efficace pour lutter contre la délinquance, il faut choisir des indicateurs pour mesurer « la délinquance » ainsi que « l’efficacité » du programme. C’est dans cette phase-là qu’interviennent inévitablement les choix et les jugements de valeur contestables que peuvent faire les chercheurs.</p><p>La recherche quantitative est parfois perçue comme plus objective parce qu’elle repose sur des chiffres, mais comme le montre <a href="http://yalebooks.com/book/9780300052596/evidence-argument-and-persuasion-policy-process" target="_blank" rel="noreferrer">Majone <span class="sr-only">(lien externe)</span></a>, les chiffres subissent des transformations. Ils commencent par être des données brutes, puis ils sont ensuite regroupés dans des catégories, comparés, et deviennent des moyennes, des taux, des ratios, des pourcentages. Chaque étape de transformation comporte un risque de partialité parce que les chercheurs choisissent les références qu’ils considèrent comme pertinentes. Par exemple, on peut choisir de montrer une augmentation du pouvoir d’achat entre deux dates, donnant une impression positive, alors que si l’on prend une période plus large on se rend compte que l’augmentation en question est dérisoire par rapport à la tendance générale à la baisse depuis plusieurs décennies. On peut aussi utiliser des éléments de langage qui changent le sens des chiffres. Par exemple, on peut choisir de dire « ce médicament guérit 70% des patients » ou alors « ce médicament échoue à sauver 30% des patients ». Les chiffres sont exactement les mêmes, mais l’effet sur le lecteur est complètement différent. On peut choisir également de montrer certains chiffres, et d’en ignorer d’autres. Par exemple, on va se réjouir des chiffres du chômage qui baissent, alors qu’ils cachent souvent l’augmentation du travail précaire.</p><p>C’est ainsi que l’on peut souvent jouer avec les chiffres, et leur faire dire ce que l’on veut. De nombreux auteurs ont montré à quel point la science était à présent devenue une arme en politique, pour donner une validation à son propos. On se sert souvent de la science pour rationaliser une décision prise en amont pour d’autres motifs. C’est souvent le prestige de la science, plutôt que la science elle-même, qui devient importante, et personne ne prend la peine de vérifier la véracité des propos. Sous couvert d’avoir « la science » de son côté, on peut justifier n’importe quelle idée. C’est une stratégie que l’on a retrouvé lors du débat sur le Brexit, lorsque l’on a vu les deux camps brandir des chiffres (souvent manipulés) pour justifier leur politique de maintien ou de sortie de l’Union Européenne. C’est entre autres le fait que la véracité des chiffres ne soit plus un argument convaincant <a href="http://www.lemonde.fr/big-browser/article/2016/07/12/les-medias-dans-l-ere-de-la-politique-post-verite_4968559_4832693.html" target="_blank" rel="noreferrer">qui a fait dire à plusieurs auteurs <span class="sr-only">(lien externe)</span></a> que nous étions entrés dans une ère « post-factuelle » ou un ère de « post-vérité ».</p><p>Une autre indication du fait que la « science » n’est pas une réalité objective est que la recherche sur un même sujet peut produire des résultats différents selon les études. Cela montre à quel point le choix du chercheur en matière d’indicateurs peut changer complètement le résultat d’une étude. En effet, le modèle idéal de l’EBPM ne prévoit pas du tout que la communauté scientifique puisse ne pas être d’accord sur les solutions à apporter à un problème. Pourtant c’est un cas de figure qui arrive assez souvent. En réalité, si l’on n’utilise pas plus souvent l’EBPM, c’est surtout parce que l’on n’arrive pas toujours à apporter une réponse claire et unanime sur les sujets qui font débat. La réalité de la recherche scientifique est que beaucoup d’études n’ont pas forcément de résultats probants. Malheureusement, la population générale et la classe politique ont souvent une culture scientifique insuffisante pour pouvoir apprécier les forces et les faiblesses de la recherche scientifique et les nuances de ses conclusions. <a href="http://www.sup.org/books/title/?id=634" target="_blank" rel="noreferrer">Hilgartner <span class="sr-only">(lien externe)</span></a> montre comment, pour que la recherche soit convaincante, la science doit souvent être mise en spectacle : les possibilités deviennent des certitudes, les doutes sont habilement passés sous silence, et de manière générale toutes les controverses méthodologiques ou les jeux de pouvoir sont maintenus en coulisses afin de garantir une image d’unicité et d’objectivité, et réussir à convaincre ceux qu’il faut convaincre.</p><p>Tous ces éléments mettent en évidence le fait que la science et les « preuves » ne sont pas des réalités objectives que le chercheur tente simplement de découvrir, et que les résultats sont liés aux questions posées et aux moyens utilisés pour les déterminer.</p><p>Enfin, outre le débat méthodologique, se pose aussi la question non moins délicate d’arriver à mesurer ce qui est important, et ne pas se contenter de rendre important ce qui est facilement mesurable. C’est particulièrement le cas en ce qui concerne les évaluations. Comme le montrent <a href="http://siteresources.worldbank.org/EASTASIAPACIFICEXT/Images/226299-1251872399239/bevanhoodpubadmin%5B1%5D.pdf" target="_blank" rel="noreferrer">Bevan et Hood <span class="sr-only">(lien externe)</span></a>, il faut faire attention au problème de la synecdoque. Comme dans la figure littéraire, lorsque l’on choisit des indicateurs, on prend une partie d’un ensemble pour représenter le tout. Mais pour que l’évaluation soit pertinente, il faut s’assurer du fait que l’on peut réellement compter sur les indicateurs choisis pour donner une représentation adéquate de l’intervention. De la même manière, il faut s’assurer que l’on n’oublie pas de rendre compte de quelque chose de fondamental, tout simplement parce que l’on n’a pas réussi à le mesurer. Dans un système où l’on ne croit que ce que l’on peut prouver, une difficulté à mesurer un phénomène peut avoir de lourdes conséquences sur le futur d’une politique. Inversement, on risque aussi de favoriser les interventions qui sont facilement mesurables. C’est pour cela qu’il est indispensable d’élargir la notion d’évaluation au-delà du simple relevé d’indicateurs.</p><p>Ce dernier point peut être illustré par la politique de santé mentale actuelle au Royaume-Uni. Depuis 2007, le gouvernement a mis en place une politique publique pour tenter d’apporter une réponse à l’épidémie de dépression et d’anxiété à laquelle fait face la population. Poursuivant l’objectif de l’EBPM, le gouvernement a décidé de se baser sur la recherche scientifique, et surtout les essais randomisés contrôlés, pour déterminer quel type de thérapie était la plus efficace pour lutter contre la dépression et l’anxiété. Après avoir fait une revue des différentes études comparant les différents types de thérapie, le gouvernement a déterminé que c’étaient les thérapies cognitives et comportementales qui étaient les plus efficaces. Cependant, une analyse précise des résultats statistiques des études montre que les thérapies cognitives et comportementales ne sont pas aussi supérieures aux autres que ce qui a été annoncé publiquement. Il s’avère en réalité que le choix de favoriser ces thérapies se base moins sur la justification scientifique de leur efficacité que sur le fait que ce sont le type de thérapies qui sont les plus faciles à évaluer, et donc pour lesquelles on a tout simplement plus d’études… Dans un contexte qui pousse à la transparence à tout prix, et à la production de chiffres pour justifier ses interventions, celles qui arrivent à en produire facilement sont souvent favorisées au détriment de celles qui y arrivent moins. Par un effet presque pervers, la pression de la transparence et de la « preuve » à tout prix peut mener à la mise en place de politiques publiques qui ne sont pas forcément les meilleures dans l’absolu.</p><p><strong><em>L’importance de l’ « irrationalité » </em></strong></p><p>Enfin, il existe une troisième catégorie de critiques qui questionne la quête de la rationalité absolue à tout prix.</p><p>L’un des postulats premiers de l’EBPM est que les décisions rationnelles sont meilleures pour la société que celles qui sont basées sur des considérations d’ordre politique ou religieux, par exemple. Cependant, pour assurer le bien-être de la société humaine, il est parfois nécessaire de faire des entorses à cet idéal et prendre en compte certaines considérations politiques, morales ou éthiques au-delà de ce qui est purement rationnel.</p><p>L’un des domaines dans lequel ces considérations prennent tout leur sens est celui de la santé. Pour un gouvernement, financer une politique de santé est généralement un financement à perte. Certes, un individu en bonne santé rapporte de l’argent au gouvernement à travers ses impôts et la richesse produite par son travail, et il est donc économiquement rationnel pour un gouvernement de maintenir ses citoyens en bonne santé. Cependant, la valeur économique d’un individu varie en fonction de son âge. Lorsqu’un individu âgé contracte une Affection de Longue Durée, il n’est plus économiquement utile au gouvernement. Néanmoins, il paraîtrait impensable de déclarer qu’on ne va pas gâcher des milliers d’euros pour sauver un homme de 85 ans atteint d’un cancer puisque son espérance de vie au départ n’est de toute façon plus très importante à ce stade-là. Le thème de l’allocation des ressources dans le domaine de la santé est un sujet fascinant où rationalité scientifique, rationalité économique, et considérations éthiques se mêlent et se débattent.</p><p>Pour reprendre l’exemple du terrorisme évoqué précédemment, il n’est certes pas <em>rationnel</em> de dépenser autant d’argent pour lutter contre les attaques terroristes si l’on ne prend en compte que le nombre de morts effectifs, par rapport aux morts causés par plein d’autres phénomènes. Cependant il y a plein d’autres facteurs qui en font une intervention légitime, comme les considérations politiques, diplomatiques, sécuritaires, ou même psychologiques. Pour éviter un vent de panique dans la population qui peut avoir des conséquences désastreuses à de nombreux niveaux, il est nécessaire d’intervenir ne serait-ce que pour avoir un effet rassurant psychologiquement. L’EBPM oublie souvent de prendre en compte l’aspect psychologique des interventions.</p><p>De manière plus générale, certaines oppositions à l’EBPM relèvent d’un débat de valeurs. Un certain nombre de personnes s’élèvent contre le culte de la rationalité à tout prix, celui de l’optimisation, du pragmatisme et de l’utilitarisme dans toutes les pratiques (voir par exemple <a href="http://www.liberation.fr/debats/2016/01/29/thibault-le-texier-nous-sommes-si-impregnes-par-la-logique-de-l-entreprise-que-nous-l-appliquons-a-n_1429856" target="_blank" rel="noreferrer">cet article de Libération <span class="sr-only">(lien externe)</span></a>). Dans une société qui prône la rationalité, la non-optimisation de ses pratiques est devenue une faute presque morale à éviter à tout prix. C’est le cas par exemple de la perte de temps et la perte d’argent. Quelqu’un qui ne sait pas faire les choses rapidement, ou qui ne sait pas trouver le meilleur rapport qualité/prix sera critiqué. Cependant les hommes ont déjà montré aux économistes classiques qu’ils ne sont pas, comme ils le pensaient au départ, des « <em>homo economicus</em> », parfaitement rationnels, qui n’ont comme seul objectif que la maximisation de leur utilité. Ils peuvent parfois faire preuve d’altruisme, se sacrifier pour le bénéfice d’un autre, changer de comportement parce qu’ils sont émus et affectés par les conditions des autres, passer du temps à contempler de l’art, trouver du plaisir à prendre leur temps pour faire les choses, ou se satisfaire de payer un prix donné, même s’il ne s’agit pas du prix le plus rentable possible. Le débat de valeur nous amène à nous demander si dans notre quête constante d’optimisation, on ne perd pas un élément essentiel à notre bien-être. <a href="http://www.ted.com/talks/barry_schwartz_on_the_paradox_of_choice?language=en" target="_blank" rel="noreferrer">Barry Schwartz <span class="sr-only">(lien externe)</span></a> nous avait déjà démontré que, contrairement à ce que l’on pourrait penser, plus on a de choix, plus on est malheureux. En effet, plus on a de choix, plus on va s’attacher à vouloir faire le meilleur des choix possibles, plus on va s’attacher à des détails insignifiants, et plus on risque d’être déçus à la fin car à la moindre imperfection on se demandera toujours si un autre choix n’aurait pas été meilleur. Alors que quelqu’un qui choisit la première option satisfaisante qu’il voit (bien que pas forcément la plus rentable rationnellement) s’épargne de nombreuses heures d’agonie à comparer tous les détails de toutes les options, ainsi que les heures à douter de son choix une fois celui-ci effectué.</p><p>Dans le contexte des politiques publiques, cela pourrait se traduire par exemple par le développement de temps purement ludiques sans aucune vocation éducative particulière dans l’organisation du temps scolaire, par le maintien d’une politique culturelle active malgré la difficulté de justifier sa plus-value avec les indicateurs et les mesures classiques d’évaluations, ou par le choix de partenaires économiquement et socialement responsables malgré leurs prix plus élevés.</p><p>————————————</p><p>En conclusion, l’EBPM est un sujet passionnant qui reflète bien l’époque dans laquelle nous nous trouvons : les progrès scientifiques élargissent le champ de nos connaissances et il est légitime de vouloir les utiliser. Nous voulons nous en servir pour améliorer les politiques publiques et les rendre plus efficaces et plus en adéquation avec les besoins des citoyens. A cela s’ajoute une volonté de rationaliser nos actions de manière générale, d’améliorer les process, de systématiser et d’optimiser nos solutions. Cependant il faut veiller à ne pas considérer l’EBPM comme une « solution miracle » et à ne pas apporter des réponses simplistes et naïves à des problèmes extrêmement complexes. Il faut également veiller à ne pas admettre aveuglément des solutions proposées parce qu’elles sont soi-disant « objectives » et « scientifiques ». Une utilisation intelligente de la recherche scientifique ne dispense pas d’avoir une pensée critique et éclairée des opportunités, mais aussi des limites, du courant « <em>evidence-based</em> ».</p>

      notes: >-
        


      alt: >-
        

      credit: >-
        




---
